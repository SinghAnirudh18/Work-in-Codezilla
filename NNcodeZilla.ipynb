{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H8yOriNF8af",
        "outputId": "9d88c647-5b71-45f8-8bae-5e4d0f5eee96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples after filtering: 4920\n",
            "Unique classes: 41\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2086 - loss: 3.3176 - val_accuracy: 0.9429 - val_loss: 1.4111\n",
            "Epoch 2/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 1.1110 - val_accuracy: 0.9975 - val_loss: 0.1145\n",
            "Epoch 3/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.2429 - val_accuracy: 1.0000 - val_loss: 0.0243\n",
            "Epoch 4/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.1182 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
            "Epoch 5/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0690 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
            "Epoch 6/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0462 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 7/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0378 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 8/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 9.4268e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 5.4662e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 4.5599e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0211 - val_accuracy: 1.0000 - val_loss: 3.8994e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 2.9095e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 1.9818e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 1.5337e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 2.0784e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 1.7809e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 6.3355e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 6.4729e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 5.1651e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 7.4314e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 4.2509e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 4.3313e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 2.2645e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 3.3461e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 1.5692e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 3.4532e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 2.3391e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 2.1433e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 2.6164e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 3.1557e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.4449e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 1.5637e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.5035e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 6.2411e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 7.1069e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 6.8641e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 5.7108e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 4.1581e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 4.7627e-06\n",
            "Epoch 41/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.2830e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 9.5283e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 4.6631e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 5.0362e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 8.3338e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 4.4398e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 2.6161e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 2.1166e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 3.5205e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.2429e-06\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2080e-06 \n",
            "Test Accuracy: 100.00%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Predicted disease for sample input: Fungal infection\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load dataset\n",
        "df = pd.read_csv('/Training.csv')\n",
        "df.columns = df.columns.str.strip()  # remove whitespace in columns\n",
        "df['prognosis'] = df['prognosis'].str.strip()\n",
        "\n",
        "# Step 2: Filter classes with at least 2 samples (to avoid stratify error)\n",
        "class_counts = df['prognosis'].value_counts()\n",
        "valid_classes = class_counts[class_counts >= 2].index\n",
        "df_filtered = df[df['prognosis'].isin(valid_classes)].reset_index(drop=True)\n",
        "\n",
        "print(f\"Total samples after filtering: {len(df_filtered)}\")\n",
        "print(f\"Unique classes: {df_filtered['prognosis'].nunique()}\")\n",
        "\n",
        "# Step 3: Prepare features and target\n",
        "X = df_filtered.drop('prognosis', axis=1).values\n",
        "y = df_filtered['prognosis']\n",
        "\n",
        "# Step 4: Encode target labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "y_categorical = to_categorical(y_encoded, num_classes=num_classes)\n",
        "\n",
        "# Step 5: Train-test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Step 6: Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(128, input_shape=(X.shape[1],), activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 7: Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 8: Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 9: Evaluate on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Step 10: Predict on a new sample (example)\n",
        "# Replace below with actual symptom input matching feature order (length == X.shape[1])\n",
        "sample_input = np.array([[1, 1, 1] + [0]*(X.shape[1]-3)])  # Example: 1s for first 3 symptoms, rest 0\n",
        "\n",
        "\n",
        "\n",
        "pred = model.predict(sample_input)\n",
        "predicted_class = encoder.inverse_transform([np.argmax(pred)])\n",
        "print(\"Predicted disease for sample input:\", predicted_class[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_disease_from_text(input_text, model, encoder, df):\n",
        "    \"\"\"\n",
        "    Predict disease from a text input of symptom names.\n",
        "\n",
        "    Args:\n",
        "        input_text (str): User input text containing symptom keywords.\n",
        "        model (keras.Model): Trained neural network model.\n",
        "        encoder (LabelEncoder): Fitted label encoder for 'prognosis'.\n",
        "        df (pd.DataFrame): The original dataset DataFrame used for training.\n",
        "\n",
        "    Returns:\n",
        "        str: Predicted disease (prognosis).\n",
        "    \"\"\"\n",
        "    # Get list of symptom columns (features) — assume all except 'prognosis'\n",
        "    symptom_columns = [col for col in df.columns if col != 'prognosis']\n",
        "\n",
        "    # Lowercase input for case-insensitive matching\n",
        "    input_text_lower = input_text.lower()\n",
        "\n",
        "    # Create feature vector filled with 0\n",
        "    input_features = np.zeros(len(symptom_columns), dtype=int)\n",
        "\n",
        "    # Map symptoms mentioned in input_text to feature vector\n",
        "    for idx, symptom in enumerate(symptom_columns):\n",
        "        # For matching, normalize symptom name by replacing underscores with spaces, lowercase\n",
        "        symptom_name = symptom.replace('_', ' ').lower()\n",
        "\n",
        "        # Check if symptom_name words are in the input text (simple substring match)\n",
        "        # You can improve this with more advanced NLP if desired\n",
        "        if symptom_name in input_text_lower:\n",
        "            input_features[idx] = 1\n",
        "\n",
        "    # Reshape and predict\n",
        "    input_features_reshaped = input_features.reshape(1, -1)\n",
        "    prediction_probs = model.predict(input_features_reshaped)\n",
        "    predicted_index = np.argmax(prediction_probs, axis=1)[0]\n",
        "    predicted_disease = encoder.inverse_transform([predicted_index])[0]\n",
        "\n",
        "    return predicted_disease\n"
      ],
      "metadata": {
        "id": "uluvtCGAIWDA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example user input\n",
        "user_input = \"Itching, skin rash, and red sore around nose\"\n",
        "# Call the prediction function\n",
        "disease_prediction = predict_disease_from_text(user_input, model, encoder, df)\n",
        "\n",
        "print(\"Predicted Disease:\", disease_prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCVfPWJLIWjb",
        "outputId": "d3d17c2b-e61e-4439-842a-733f0e3c7893"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Predicted Disease: Impetigo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pkl', 'wb') as le_file:\n",
        "    pickle.dump(encoder, le_file)"
      ],
      "metadata": {
        "id": "tOjp7DIcIaXJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model.save('disease_prediction_model.h5')\n",
        "print(\"Model saved to disease_prediction_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv0sjHhab7JT",
        "outputId": "fb8ed458-205f-4358-cad6-feab744d2965"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to disease_prediction_model.h5\n"
          ]
        }
      ]
    }
  ]
}